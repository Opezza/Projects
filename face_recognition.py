# -*- coding: utf-8 -*-
"""ML&BD_LAB10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QvoZmo2KWMNetNl2V2w-9ZyBPN6LaBra
"""

!apt-get update
!apt-get install -y build-essential cmake
!apt-get install -y libopenblas-dev liblapack-dev
!apt-get install -y libx11-dev libgtk-3-dev
!pip install dlib

!wget   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # DOWNLOAD LINK

!bunzip2 /content/shape_predictor_68_face_landmarks.dat.bz2

datFile =  "/content/shape_predictor_68_face_landmarks.dat"

import dlib
from google.colab.patches import cv2_imshow
import cv2
from skimage import io
from scipy.spatial import distance

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

"""wykrywanie sławnej osoby"""

# Wczytanie obrazu
image1 = cv2.imread("rober1.png")

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)

    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image1, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image1, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image1)

# Wczytanie obrazu
image2 = cv2.imread("robert2.png")

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)

    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image2, (x, y), (x+w, y+h), (0, 255, 0), 2)

    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image2, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image2)

# Ścieżki do zdjęć
image1_path = "rober1.png"
image2_path = "robert2.png"

# Porównaj oba zdjęcia
compare_images(image1_path, image2_path)

# Wczytaj obrazy twarzy
image1 = cv2.imread('rober1.png')
image2 = cv2.imread('robert2.png')

# Przekonwertuj obrazy na skale szarości
gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

# Utwórz detektor twarzy
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')

# Wykryj twarze na obrazach
faces1 = face_cascade.detectMultiScale(gray1, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
faces2 = face_cascade.detectMultiScale(gray2, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

# Wyświetl twarze na obrazach
for (x, y, w, h) in faces1:
    cv2.rectangle(image1, (x, y), (x+w, y+h), (0, 255, 0), 2)

for (x, y, w, h) in faces2:
    cv2.rectangle(image2, (x, y), (x+w, y+h), (0, 255, 0), 2)

# Wyświetl wynik
cv2_imshow(image1)
cv2_imshow(image2)

# Pobierz wymiary obrazu
height, width, channels = image1.shape

print(f'Wymiary obrazu: {width}x{height}')

img1=image1[0:500, 0:960]
cv2_imshow(img1)
cv2.imwrite('robert1.png', img1)

img1="robert1.png"

# Porównaj oba zdjęcia
compare_images(img1, image2_path)

!pip3 install face_recognition

import face_recognition

# Wczytaj obrazy twarzy
image_group = face_recognition.load_image_file("grupa.png")
image_single = face_recognition.load_image_file("harry.jpg")

# Wyszukaj twarze na obrazach
face_locations_group = face_recognition.face_locations(image_group)
face_locations_single = face_recognition.face_locations(image_single)

# Koduj twarze
face_encodings_group = face_recognition.face_encodings(image_group, face_locations_group)
face_encodings_single = face_recognition.face_encodings(image_single, face_locations_single)

# Porównaj twarze
results = []
for face_encoding_single in face_encodings_single:
    distances = face_recognition.face_distance(face_encodings_group, face_encoding_single)
    min_distance_index = distances.argmin()
    min_distance = distances[min_distance_index]
    results.append((min_distance_index, min_distance))

# Posortuj wyniki wg odległości
results = sorted(results, key=lambda x: x[1])

# Wybierz najbardziej podobną osobę
most_similar_person_index, similarity = results[0]

# Wyświetl wyniki
print(f"Najbardziej podobna osoba znajduje się na pozycji {most_similar_person_index + 1} na zdjęciu grupowym.")
print(f"Ocena podobieństwa: {similarity}")